# 카프카 기본 개념-2
> 복제, ISR, 토픽과 파티션, 레코드, 클라이언트 메타데이터

<br>

## 브로커의 역할 - 복제(Replication)
![image](https://github.com/dlask913/TIL/assets/79985588/692a19f8-5cc3-4894-a7eb-8879217b13e8)
- 데이터의 유실을 방지하고자 파티션 단위로 각각의 브로커에 데이트를 분산해서 저장하는 것을 말한다. 
- 토픽을 생성할 때 파티션의 복제 개수도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다. 1(복제 없음) ~ 최대 브로커 개수
- 복제된 파티션은 리더와 팔로워로 구성되며 프로듀서 및 컨슈머와 통신하는 역할은 리더 파티션이, 복제는 팔로워 파티션들이 한다.
- 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 **복제**한다.

1. 단점
- 복제 개수 만큼 저장 용량이 증가된다.
- 서버는 해커로 인한 침입, 디스크 오류, 네트워크 연결 장애 등의 이유로 언제든 장애가 발생할 수 있다.

2. 장점
- 복제를 통해 데이터를 안전하게 사용할 수 있다는 강력한 장점 때문에 카프카를 운영할 때 2 이상의 복제 개수를 정하는 것이 중요하다.
- 데이터가 일부 유실되어도 무관하고 데이터 처리 속도가 중요하다면 1 또는 2로 설정한다. ( GPS 정보와 같은 메트릭 등 )
- 금융 정보와 같이 유실이 일어나면 안되는 데이터의 경우 복제 개수를 3으로 설정한다.

3. 승급
- 브로커가 다운되면 해당 브로커에 있는 리더 파티션은 사용할 수 없기 때문에 팔로워 파티션 중 하나가 리더 파티션 지위를 넘겨받는다.

<br>

## ISR ( In-Sync-Replicas)
-  ISR 은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 말한다. ( 오프셋 크기가 같음 ) 
- 동기화가 완료됐다는 의미는 리더 파티션의 모든 데이터가 팔로워 파티션에 복제된 상태를 말한다.
- 복제가 되지 않은 상태에서 장애가 발생하면 싱크가 되지 않은 팔로워 파티션이 리더 파티션으로 선출되어 데이터가 유실될 수 있는데 이 때 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶다면 ISR 이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.
> unclean.leader.election.enable = true : 유실 감수, 복제가 안된 팔로워 파티션을 리더로 승급<br> unclean.leader.election.enable = false : 유실 감수 X, 해당 브로커가 복구될 때까지 중단.<br> ->토픽 단위로 설정 가능

<br>

## 토픽과 파티션
- 토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위. 토픽은 1개 이상의 파티션을 소유. 
- 레코드 : 파티션에 저장되는 프로듀서가 보낸 데이터 (메시지 키/값)
- 파티션 : 큐와 비슷한 구조로, FIFO. 먼저 들어간 레코드는 컨슈머가 먼저 가져가게 되고 데이터는 삭제되지 않는다. 

파티션이 5개인 토픽을 생성했을 경우 0번 브로커부터 시작하여 round-robin 방식으로 리더 파티션들이 생성된다. 카프카 클라이언트는 리더 파티션이 있는 브로커와 통신하여 데이터를 주고 받으므로 여러 브로커에 골고루 네트워크 통신을 하게 된다. 이를 통해, 데이터가 특정 서버와 통신이 집중되는 현상을 막고 선형 확장을 하여 데이터가 많아지더라도 자연스럽게 대응할 수 있다.

특정 브로커에 파티션이 몰리는 경우에는 kafka-reassign-partitions.sh 명령으로 파티션을 재분배할 수 있다. 

### 파티션 개수와 컨슈머 개수의 처리량
-  보통은 1:1 관계이고 파티션 하나는 최대 1개의 파티션만 가질 수 있으며, 컨슈머의 데이터 처리량을 늘리기 위해서는 파티션도 같이 늘려야 한다.  
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것으로, 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.

### 파티션 개수를 줄이는 것은 불가능 ( 지원 X )
-  한 번 파티션을 늘리면 불가능하기 때문에 토픽을 삭제하고 재생성하는 방법 외에 없다. 
- 카프카에서는 파티션의 데이터를 세그먼트로 저장하고 있으며 만에 하나 지원한다 하더라도 여러 브로커에 저장된 데이터를 취합하고 정렬해야하는 복잡한 과정을 거쳐야 하기 때문에 클러스터에 큰 영향이 가게 된다. 

<br>

## 레코드
: 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다. 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다. 브로커에 한 번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

### 1. 타임스탬프
- 스트림 프로세싱에서 활용하기 위한 시간을 저장하는 용도로 사용. 
- 0.10.0.0 이후 버전부터 추가된 타임스탬프는 Unix timestamp 가 포함되며 프로듀서에서 따로 설정하지 않으면 기본값으로 ProducerRecord 생성 시간(CreateTime) 이 들어간다. 
- 브로커 적재 시간 ( LogAppendTime ) 으로 설정할 수도 있다. 
> 해당 옵션은 토픽 단위로 설정 가능하며 message.timestamp.type 을 사용한다.

### 2. 오프셋
- 프로듀서가 생성한 레코드에는 존재 X. 
- 프로듀서가 전송한 레코드가 브로커에 적재될 때 오프셋이 지정된다. ( 0부터 1씩 증가 ) 
- 컨슈머는 오프셋을 기반으로 처리가 완료된 데이터와 앞으로 처리해야할 데이터를 구분한다. 
- 각 메시지는 파티션 별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리르 방지하기 위한 목적으로도 사용한다. 

### 3. 헤더
- 0.11 부터 제공된 기능. key/value 데이터를 추가할 수 있으며 레코드의 스키마 버전이나 포맷과 같이 데이터 프로세싱에 참고할만한 정보를 담아서 사용할 수 있다. 

### 4. 메시지 키
- 메시지 값을 분류하기 위한 용도 -> 파티셔닝. 
- 파티셔닝에 사용하는 메시지 키는 파티셔너(Partitioner) 에 따라 토픽의 타피션 번호가 정해진다. 필수 값이 아니며 지정하지 않으면 null 로 설정된다. ( 라운드 로빈으로 전달 ) null 이 아닌 메시지 키는 해쉬값에 의해서 특정 파티션에 매핑되어 전달된다. ( 기본 파티셔너의 경우 )

### 5. 메시지 값
- 실질적으로 처리할 데이터가 담기는 공간. 
- 메시지 값의 포맥은 Generic 으로 사용자에 의해 지정된다. ( Float, Bytep[], String, 사용자 지정 포맷으로 직렬화/역직렬화 등) 
- 브로커에 저장된 레코드의 메시지 값은 어떤 포맷으로 직렬화되어 저장되었는 지 알 수 없기 때문에 컨슈머는 미리 역직렬화 포맷을 알고 있어야 한다. 

<br>

## 클라이언트 메타데이터
: 카프카 클라이언트(프로듀서/컨슈머)는 통신하고자 하는 리더 파티션의 위치를 알기 위해 데이터를 주고(프로듀서) 받기(컨슈머) 전에 메타데이터를 브로커로부터 전달받는다. 메타데이터는 다음과 같은 옵션을 통해 리프레쉬된다.
- 카프카 프로듀서 메타데이터 옵션
> metadata.max.age.ms : 메타데이터를 강제로 리프레시하는 간격 ( 기본값 5분 ) <br> metadata.max.idle.ms : 프로듀서가 유휴상태일 경우 메타데이터를 캐시에 유지하는 기간. 예를 들어 프로듀서가 특정 토픽으로 데이터를 보낸 이후 지정한 시간이 지나고 나면 강제로 메타데이터를 리프레시 ( 기본값 5분 )

### 클라이언트 메타데이터에 이슈가 발생한 경우
: 만약 메타데이터가 현재의 파티션 상태에 맞게 리프레시되지 않은 상태에서 잘못된 데이터를 요청하면 LEADER_NOT_AVAILABLE Exception 이 발생한다. 이 에러는 클라이언트(프로듀서/컨슈머)가 데이터를 요청한 브로커에 리더 파티션이 없는 경우 나타나며 대부분의 경우 메타데이터 리프레시 이슈로 발생한다. -> 리프레시 간격 확인

<br>

## 참고
[아파치 카프카 애플리케이션 프로그래밍](https://inf.run/uCwV5)